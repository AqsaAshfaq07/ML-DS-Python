# -*- coding: utf-8 -*-
"""Deep_Learning_with_Tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZzKQHS4ibcTM1PZEW-igdR_ROC1kqIsz
"""

# TensorFlow -> Deep Learning Framework 
# Tensors -> multidimensional matrices / anything with numeric values

import tensorflow as tf
from tensorflow import keras

print("tensorflow version: " , tf.__version__)

mnist = tf.keras.datasets.mnist
(X_train, y_train), (X_test, y_test) = mnist.load_data()
X_train, X_test = X_train/255.0, X_test/255.0   # dividing by 255 to convert all values from 0-1 range

# Build a Machine Learning Model
model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation = 'relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10)
])
X = tf.ones((3,3,))

predictions = model(X_train[:1])
predictions

# Convert these logits to probabilities for each class
import numpy
tf.nn.softmax(predictions)

# Define a loss function for training
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)
loss_fn

loss_fn(y_train[:1], predictions)

# Before Training, compile the model
model.compile(optimizer = 'adam', loss= loss_fn, metrics = ['accuracy'])

# Train and Evaluate the Model
model.fit(X_train, y_train, epochs = 5)

model.evaluate(X_test, y_test, verbose = 2)

prob_model = tf.keras.Sequential(
    model, 
    tf.keras.layers.Softmax()
)

# prob_model.compile(optimizer = 'adam', loss= None, metrics= ['accuracy'])
# prob_model.fit(X_train, y_train, epochs = 5)
# prob_model.evaluate(X_test, y_test, verbose = 3)

# Multi layer perceptrons -> neural networks containing multiple hidden layers
tf.compat.v1.disable_eager_execution()
tf.compat.v1.placeholder(dtype = tf.int32, shape = (28, 28), name = 'inputs')

# LOGITS

# Produce a single layer perceptron
import numpy as np
# x = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0])
# tf.math.reduce_mean(x, axis = None, name = None, keepdims = False)
y_train = y_train.astype(np.float32)
probs = tf.math.sigmoid(y_train) # here presenting LOGITS
rounded_probs = tf.math.round(probs)

predictions.shape
y_test.resize(60000, refcheck = False)  # changing size of y_test to make predictions and y_test of equal dimensions
y_test.shape

predictions = tf.cast(rounded_probs , tf.int32)

# checking the accuracy
is_correct = tf.math.equal(predictions, y_test)

is_correct_float = tf.cast(is_correct, tf.float32)
accuracy = tf.math.reduce_mean(is_correct_float)

#OPTIMIZATION
# Gradient Descent -- optimization algorithm used to reduce the loss function
# AdamOptimizer -> learning_rate values already defines
y_test_float = tf.cast(y_test, tf.float32)
predictions = tf.cast(predictions, tf.float32)
# Finding cross entropy
cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_test_float, logits=predictions)
loss = tf.math.reduce_mean(cross_entropy)

adam = tf.compat.v1.train.AdamOptimizer()
#predictions = adam.minimize(loss)

# Training
with tf.compat.v1.Session() as sess:
  t = tf.constant([1, 2, 4])
  arr = sess.run(t)

  t2 = tf.constant([5, 6, 8])
  sess.run((t, t2))

with tf.compat.v1.Session() as sess:
  inputs = tf.compat.v1.placeholder(tf.float32, shape = (None, 2))
  feed_dict = {
      inputs : [[1.2, 4], [-3.5, 6]]
  }
  sess.run(inputs, feed_dict = feed_dict)



with tf.compat.v1.Session() as sess:
  inputs = tf.compat.v1.placeholder(tf.float32, shape = (None, 2))
  feed_dict = {
      inputs : [[1.2, 4], [-3.5, 6]]
  }
  logits = tf.keras.layers.Dense(units =1, name='logits')(inputs)
  init_op = tf.compat.v1.global_variables_initializer()
  sess.run(init_op)
  arr = sess.run(logits, feed_dict = feed_dict)
  print(repr(arr))  # repr -> gives printable reperesentation of the given object

# Evaluate
feed_dict = {
    inputs: X_test
}
eval_acc = sess.run(accuracy, feed_dict = feed_dict)
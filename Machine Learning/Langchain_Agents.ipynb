{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMaiflqY-MHu",
        "outputId": "a060b663-7deb-4380-bbdf-17fb3e32e02c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain-openai langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo\", openai_api_key= userdata.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "MmgsSW8I-Ut5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a Tool\n",
        "\n",
        "from langchain.agents import load_tools, Tool\n",
        "from langchain.chains import LLMMathChain, LLMChain\n",
        "\n",
        "tools = load_tools(['llm-math'], llm = llm)"
      ],
      "metadata": {
        "id": "EiBlVehj-vEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools[0].name\n",
        "tools[0].description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Iyw3vxSf_M6z",
        "outputId": "fa548919-f142-4896-ebe6-08de07659e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Useful for when you need to answer questions about math.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make an Agent\n",
        "\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "agent = initialize_agent(\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=4,\n",
        ")"
      ],
      "metadata": {
        "id": "ZY940S1gACGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent(\"What is 2*2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMI3FjIHBO4P",
        "outputId": "cabdf4a3-aa16-4a65-fd4b-563fa0ed7db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use the Calculator tool to multiply 2 by 2.\n",
            "Action: Calculator\n",
            "Action Input: 2*2\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 4\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: 4\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is 2*2', 'output': '4'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new tool\n",
        "\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=\"{query}\",\n",
        ")\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "llm_tool = Tool(\n",
        "    name=\"llm-tool\",\n",
        "    func=llm_chain.run,\n",
        "    description=\"This tool helps answer general queries.\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngGmZeBtAZ-j",
        "outputId": "a911e99c-f33d-44f9-981e-e0a3f8ba45d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools.append(llm_tool)\n",
        "\n",
        "# reinitialize the zero shot agent\n",
        "agent = initialize_agent(\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=4,\n",
        ")"
      ],
      "metadata": {
        "id": "OlLzgW_cC55i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent(\"How can I help you today\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtumzG9YDJFk",
        "outputId": "b0a1e5c9-5db7-4e4e-d1ee-c0a263f23a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to use the tools provided to answer the question.\n",
            "Action: llm-tool\n",
            "Action Input: How can I help you today\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAs a language model AI, I am here to assist you with any questions or tasks you may have. Just let me know how I can help you today!\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI need to ask a more specific question to get the assistance I need.\n",
            "Action: llm-tool\n",
            "Action Input: Can you provide me with information on the weather in New York City?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mSure! Here is some information on the weather in New York City:\n",
            "\n",
            "- New York City experiences all four seasons, with hot summers and cold winters.\n",
            "- The average high temperature in the summer months (June-August) is around 80-85°F (27-29°C), while the average low temperature is around 65-70°F (18-21°C).\n",
            "- The winter months (December-February) are much colder, with average high temperatures around 35-40°F (1-4°C) and average low temperatures around 25-30°F (-4 to -1°C).\n",
            "- New York City also experiences a fair amount of precipitation throughout the year, with an average of around 45 inches of rain and 25 inches of snow annually.\n",
            "- The city can also be quite humid, especially in the summer months, with average humidity levels around 60-80%.\n",
            "\n",
            "Overall, New York City experiences a mix of weather conditions throughout the year, so it's important to check the forecast before planning your visit.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now have the information on the weather in New York City.\n",
            "Final Answer: The weather in New York City includes hot summers, cold winters, and a fair amount of precipitation throughout the year.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'How can I help you today',\n",
              " 'output': 'The weather in New York City includes hot summers, cold winters, and a fair amount of precipitation throughout the year.'}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agents Types\n",
        "\n",
        "1- Zero Shot ReAct Agent\n",
        "-- agent has no memory - just performs single time task\n",
        "\n",
        "Agents are better than chains as they can perform multiple steps and give a refined output. They go through a step by step thought process.\n",
        "\n",
        "2- Conversational ReAct Agent\n",
        "-- can remember conversations and helpful in building conversational chatbots\n",
        "\n",
        "3- ReAct Docstore\n",
        "-- helps retrieve information using Search and Lookup methods\n",
        "\n",
        "4- Self Ask with Search\n",
        "-- helps when integrating live search with a chatbot"
      ],
      "metadata": {
        "id": "H5bFAuGkDVq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
      ],
      "metadata": {
        "id": "2pNKmafHH9T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize an agent similar to the last one\n",
        "\n",
        "conversational_agent = initialize_agent(\n",
        "    agent=\"conversational-react-description\",\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=4,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "ngc1FT-1INgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_agent(\"I need your help today!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agZUFHUZIc9J",
        "outputId": "782165ea-806f-4221-f4c0-08f47f7e8296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Of course! How can I assist you today?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'I need your help today!',\n",
              " 'chat_history': \"Human: I need your help today!\\nAI: Of course! I'm here to help. What do you need assistance with today?\",\n",
              " 'output': 'Of course! How can I assist you today?'}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_agent(\"I am suffering from fever. Tell me some doctors to visit in Lahore DHA!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_lDarzOIjFu",
        "outputId": "5cbbb538-0b38-4cd4-cac3-97d75856b489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: llm-tool\n",
            "Action Input: \"List of doctors to visit in Lahore DHA for fever\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m1. Dr. Talat Mehmood - Mehmood Hospital, Phase 6, DHA\n",
            "2. Dr. Shahzad Nasim - Hameed Latif Hospital, Phase 5, DHA\n",
            "3. Dr. Asma Ajmal - National Hospital, Phase 1, DHA\n",
            "4. Dr. M. Ali Tirmizi - Shaukat Khanum Memorial Cancer Hospital, Phase 5, DHA\n",
            "5. Dr. Faheem Arshad - Bahria Town International Hospital, Sector C, DHA\n",
            "6. Dr. Anwar Aman - Defence Medical Centre, Phase 2, DHA\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: Here is a list of doctors to visit in Lahore DHA for fever:\n",
            "1. Dr. Talat Mehmood - Mehmood Hospital, Phase 6, DHA\n",
            "2. Dr. Shahzad Nasim - Hameed Latif Hospital, Phase 5, DHA\n",
            "3. Dr. Asma Ajmal - National Hospital, Phase 1, DHA\n",
            "4. Dr. M. Ali Tirmizi - Shaukat Khanum Memorial Cancer Hospital, Phase 5, DHA\n",
            "5. Dr. Faheem Arshad - Bahria Town International Hospital, Sector C, DHA\n",
            "6. Dr. Anwar Aman - Defence Medical Centre, Phase 2, DHA\n",
            "\n",
            "I hope this information helps! Let me know if you need any more assistance.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'I am suffering from fever. Tell me some doctors to visit in Lahore DHA!',\n",
              " 'chat_history': \"Human: I need your help today!\\nAI: Of course! I'm here to help. What do you need assistance with today?\\nHuman: I need your help today!\\nAI: Of course! How can I assist you today?\",\n",
              " 'output': 'Here is a list of doctors to visit in Lahore DHA for fever:\\n1. Dr. Talat Mehmood - Mehmood Hospital, Phase 6, DHA\\n2. Dr. Shahzad Nasim - Hameed Latif Hospital, Phase 5, DHA\\n3. Dr. Asma Ajmal - National Hospital, Phase 1, DHA\\n4. Dr. M. Ali Tirmizi - Shaukat Khanum Memorial Cancer Hospital, Phase 5, DHA\\n5. Dr. Faheem Arshad - Bahria Town International Hospital, Sector C, DHA\\n6. Dr. Anwar Aman - Defence Medical Centre, Phase 2, DHA\\n\\nI hope this information helps! Let me know if you need any more assistance.'}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_agent(\"They all are too costly. Suggest me some cheap ones.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBvuDu3GIoNe",
        "outputId": "9f1c2047-5a17-4ce9-e3d7-6ff1d7e63a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: I understand that cost can be a concern when looking for healthcare options. Here are some more affordable options to consider for fever treatment in Lahore DHA:\n",
            "1. Dr. Nadeem Fazal - Saifee Hospital, Phase 1, DHA\n",
            "2. Dr. Farah Saeed - Iqra Medical Complex, Phase 1, DHA\n",
            "3. Dr. Ayesha Javed - Defence Medical Centre, Phase 2, DHA\n",
            "4. Dr. Ahsan Raza - Ittefaq Hospital, Phase 2, DHA\n",
            "5. Dr. Yasir Iqbal - Bahria International Hospital, Sector B, DHA\n",
            "\n",
            "I hope these options are more budget-friendly for you. Let me know if you need any more assistance.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'They all are too costly. Suggest me some cheap ones.',\n",
              " 'chat_history': \"Human: I need your help today!\\nAI: Of course! I'm here to help. What do you need assistance with today?\\nHuman: I need your help today!\\nAI: Of course! How can I assist you today?\\nHuman: I am suffering from fever. Tell me some doctors to visit in Lahore DHA!\\nAI: Here is a list of doctors to visit in Lahore DHA for fever:\\n1. Dr. Talat Mehmood - Mehmood Hospital, Phase 6, DHA\\n2. Dr. Shahzad Nasim - Hameed Latif Hospital, Phase 5, DHA\\n3. Dr. Asma Ajmal - National Hospital, Phase 1, DHA\\n4. Dr. M. Ali Tirmizi - Shaukat Khanum Memorial Cancer Hospital, Phase 5, DHA\\n5. Dr. Faheem Arshad - Bahria Town International Hospital, Sector C, DHA\\n6. Dr. Anwar Aman - Defence Medical Centre, Phase 2, DHA\\n\\nI hope this information helps! Let me know if you need any more assistance.\",\n",
              " 'output': 'I understand that cost can be a concern when looking for healthcare options. Here are some more affordable options to consider for fever treatment in Lahore DHA:\\n1. Dr. Nadeem Fazal - Saifee Hospital, Phase 1, DHA\\n2. Dr. Farah Saeed - Iqra Medical Complex, Phase 1, DHA\\n3. Dr. Ayesha Javed - Defence Medical Centre, Phase 2, DHA\\n4. Dr. Ahsan Raza - Ittefaq Hospital, Phase 2, DHA\\n5. Dr. Yasir Iqbal - Bahria International Hospital, Sector B, DHA\\n\\nI hope these options are more budget-friendly for you. Let me know if you need any more assistance.'}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9B2-xjkLozc",
        "outputId": "813010be-0440-40bb-a994-77617a2587b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ReAct Docstore\n",
        "\n",
        "from langchain import Wikipedia\n",
        "from langchain.agents.react.base import DocstoreExplorer\n",
        "\n",
        "docstore=DocstoreExplorer(Wikipedia())\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Search\",\n",
        "        func=docstore.search,\n",
        "        description='search wikipedia'\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Lookup\",\n",
        "        func=docstore.lookup,\n",
        "        description='lookup a term in wikipedia'\n",
        "\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "2Ba1nokaKEnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docstore_agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=\"react-docstore\",\n",
        "    verbose=True,\n",
        "    max_iterations=4,\n",
        "    handle_parsing_errors=True,\n",
        ")"
      ],
      "metadata": {
        "id": "4IAFyJ3mKnRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docstore_agent(\"Tell me about this agent?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMlLtBJOL86k",
        "outputId": "551cd1f4-6d83-40ed-c699-13f446e43c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mCould not parse action directive: Ask for the name of the agent or specific details to conduct a search.\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM Output: I need more specific details about the agent to conduct a search.\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM Output: To provide relevant information about the agent, I would need a specific name or details to conduct a search. Please provide more specific information or details about the agent.\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM Output: To answer a question about an agent, I would need more specific details such as a name or specific characteristics to conduct a search and provide relevant information.\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Tell me about this agent?',\n",
              " 'output': 'Agent stopped due to iteration limit or time limit.'}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73mk3vjyN28k",
        "outputId": "585012cf-0c0c-4921-ac16-40de159f8fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Self-Ask with Search\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "search = ChatOpenAI(openai_api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Intermediate Answer\",\n",
        "        func=search.invoke,\n",
        "        description='google search'\n",
        "    )\n",
        "]\n",
        "\n",
        "# initialize the search enabled agent\n",
        "self_ask_with_search = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=\"self-ask-with-search\",\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")"
      ],
      "metadata": {
        "id": "7ILZEcs4MDcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self_ask_with_search(\"who died first; Plato, Socrates, or Aristotle?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K--sIjS_N04s",
        "outputId": "1c5c074c-6d93-4e28-a2a5-d7e4c6de639f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mCould not parse output: Yes.\u001b[0m\n",
            "Intermediate answer: Invalid or incomplete response\n",
            "\u001b[32;1m\u001b[1;3mFollow up: When did Plato die?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3mcontent='Plato died in 347 BC.' response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 12, 'total_tokens': 20}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-570234ee-bc5b-4499-b341-180ac20f888d-0' usage_metadata={'input_tokens': 12, 'output_tokens': 8, 'total_tokens': 20}\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFollow up: When did Socrates die?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3mcontent='Socrates died in 399 BC.' response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 13, 'total_tokens': 21}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-91b97e3c-81f3-430b-ace3-843617451975-0' usage_metadata={'input_tokens': 13, 'output_tokens': 8, 'total_tokens': 21}\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFollow up: When did Aristotle die?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3mcontent='Aristotle died in 322 BC.' response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 12, 'total_tokens': 21}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-abb28648-a5d3-48e5-9779-7254e721060b-0' usage_metadata={'input_tokens': 12, 'output_tokens': 9, 'total_tokens': 21}\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mSo the final answer is: Socrates\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'who died first; Plato, Socrates, or Aristotle?',\n",
              " 'output': 'Socrates'}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore More on Your Own for more agents :)"
      ],
      "metadata": {
        "id": "vq8ZCwD3PzG1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
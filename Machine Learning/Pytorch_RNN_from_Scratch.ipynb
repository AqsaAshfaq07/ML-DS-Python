{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvkGB3Tw0RJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd9c203b-6c9d-43a9-9118-3629253aa07f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2814k  100 2814k    0     0  8296k      0 --:--:-- --:--:-- --:--:-- 8302k\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ]
        }
      ],
      "source": [
        "!curl -O https://download.pytorch.org/tutorial/data.zip; unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCYAI_qqcO_u",
        "outputId": "664b6788-64fc-4785-ff03-7b69e579bb7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from string import ascii_letters\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from unidecode import unidecode\n",
        "\n",
        "_ = torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "VtqSY3WxbbfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"./data/names\"\n",
        "\n",
        "lang2label = {\n",
        "    file_name.split(\".\")[0]: torch.tensor([i], dtype=torch.long)\n",
        "    for i, file_name in enumerate(os.listdir(data_dir))\n",
        "}"
      ],
      "metadata": {
        "id": "rZ5UGWzHcagr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmzyiSKacK7c",
        "outputId": "c539bf0e-d633-41e8-bb26-fb488d09ac3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Russian': tensor([0]),\n",
              " 'Spanish': tensor([1]),\n",
              " 'Portuguese': tensor([2]),\n",
              " 'Arabic': tensor([3]),\n",
              " 'Greek': tensor([4]),\n",
              " 'German': tensor([5]),\n",
              " 'French': tensor([6]),\n",
              " 'Korean': tensor([7]),\n",
              " 'Dutch': tensor([8]),\n",
              " 'Irish': tensor([9]),\n",
              " 'Scottish': tensor([10]),\n",
              " 'Italian': tensor([11]),\n",
              " 'Polish': tensor([12]),\n",
              " 'Chinese': tensor([13]),\n",
              " 'Czech': tensor([14]),\n",
              " 'Vietnamese': tensor([15]),\n",
              " 'English': tensor([16]),\n",
              " 'Japanese': tensor([17])}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_langs = len(lang2label)"
      ],
      "metadata": {
        "id": "dnwikUPtc_2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unidecode(\"Ślusàrski\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3oj9wtSvdBsp",
        "outputId": "be9a8240-8c4f-4772-d413-cd33793eb5f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Slusarski'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx = {letter: i for i, letter in enumerate(ascii_letters + \" .,:;-'\")}\n",
        "num_letters = len(char2idx); num_letters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43Yy73N4dQ3C",
        "outputId": "da1107a9-b594-4018-9690-1c1e3cbe8522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def name2tensor(name):\n",
        "    tensor = torch.zeros(len(name), 1, num_letters)\n",
        "    for i, char in enumerate(name):\n",
        "        tensor[i][0][char2idx[char]] = 1\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "Hun8vWB5dwIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name2tensor(\"Aqsa\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyliqIE3ec8O",
        "outputId": "f564b7fa-7252-47cc-c2d2-7d8d5211eb10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_names = []\n",
        "target_langs = []\n",
        "\n",
        "for file in os.listdir(data_dir):\n",
        "    with open(os.path.join(data_dir, file)) as f:\n",
        "        lang = file.split(\".\")[0]\n",
        "        names = [unidecode(line.rstrip()) for line in f]\n",
        "        for name in names:\n",
        "            try:\n",
        "                tensor_names.append(name2tensor(name))\n",
        "                target_langs.append(lang2label[lang])\n",
        "            except KeyError:\n",
        "                pass"
      ],
      "metadata": {
        "id": "I0ZkiVNKhlGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_idx, test_idx = train_test_split(\n",
        "    range(len(target_langs)),\n",
        "    test_size = 0.1,\n",
        "    shuffle = True,\n",
        "    stratify = target_langs\n",
        ")\n",
        "\n",
        "train_dataset = [\n",
        "    (tensor_names[i], target_langs[i])\n",
        "    for i in train_idx\n",
        "]\n",
        "\n",
        "test_dataset = [\n",
        "    (tensor_names[i], target_langs[i])\n",
        "    for i in test_idx\n",
        "]"
      ],
      "metadata": {
        "id": "EU_QR4GGiTav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset); len(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLSidzceijg7",
        "outputId": "f80a4f3f-b51a-483e-8113-6a37815709c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2007"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple RNN"
      ],
      "metadata": {
        "id": "6YF0KhV9rRUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MyRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.in2hidden = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.in2output = nn.Linear(input_size + hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden_state):\n",
        "        combined = torch.cat((x, hidden_state), 1)\n",
        "        hidden = torch.sigmoid(self.in2hidden(combined))\n",
        "        output = self.in2output(combined)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return nn.init.kaiming_uniform_(torch.empty(1, self.hidden_size))"
      ],
      "metadata": {
        "id": "lNCP0Q4Kidqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = MyRNN(num_letters, hidden_size, num_langs)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "RWmYgaKGmxpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "print_interval = 6000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    random.shuffle(train_dataset)\n",
        "    for i, (name, label) in enumerate(train_dataset):\n",
        "        hidden_state = model.init_hidden()\n",
        "        for char in name:\n",
        "            output, hidden_state = model(char, hidden_state)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % print_interval == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
        "                f\"Step [{i + 1}/{len(train_dataset)}], \"\n",
        "                f\"Loss: {loss.item():.4f}\"\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSnbD6I7nhn_",
        "outputId": "2077bdaf-4af0-4e2c-dbd0-37678588be92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [6000/18063], Loss: 2.4170\n",
            "Epoch [1/10], Step [12000/18063], Loss: 0.6860\n",
            "Epoch [1/10], Step [18000/18063], Loss: 6.1761\n",
            "Epoch [2/10], Step [6000/18063], Loss: 6.3844\n",
            "Epoch [2/10], Step [12000/18063], Loss: 0.0000\n",
            "Epoch [2/10], Step [18000/18063], Loss: 2.7758\n",
            "Epoch [3/10], Step [6000/18063], Loss: 0.1898\n",
            "Epoch [3/10], Step [12000/18063], Loss: 0.0033\n",
            "Epoch [3/10], Step [18000/18063], Loss: 0.1699\n",
            "Epoch [4/10], Step [6000/18063], Loss: 0.0042\n",
            "Epoch [4/10], Step [12000/18063], Loss: 6.3242\n",
            "Epoch [4/10], Step [18000/18063], Loss: 0.0284\n",
            "Epoch [5/10], Step [6000/18063], Loss: 0.0142\n",
            "Epoch [5/10], Step [12000/18063], Loss: 0.0775\n",
            "Epoch [5/10], Step [18000/18063], Loss: 0.0000\n",
            "Epoch [6/10], Step [6000/18063], Loss: 0.0269\n",
            "Epoch [6/10], Step [12000/18063], Loss: 0.0000\n",
            "Epoch [6/10], Step [18000/18063], Loss: 3.9840\n",
            "Epoch [7/10], Step [6000/18063], Loss: 2.3213\n",
            "Epoch [7/10], Step [12000/18063], Loss: 5.7301\n",
            "Epoch [7/10], Step [18000/18063], Loss: 1.8057\n",
            "Epoch [8/10], Step [6000/18063], Loss: 0.1318\n",
            "Epoch [8/10], Step [12000/18063], Loss: 0.0003\n",
            "Epoch [8/10], Step [18000/18063], Loss: 5.2463\n",
            "Epoch [9/10], Step [6000/18063], Loss: 6.2051\n",
            "Epoch [9/10], Step [12000/18063], Loss: 0.0443\n",
            "Epoch [9/10], Step [18000/18063], Loss: 0.0000\n",
            "Epoch [10/10], Step [6000/18063], Loss: 0.0001\n",
            "Epoch [10/10], Step [12000/18063], Loss: 0.3243\n",
            "Epoch [10/10], Step [18000/18063], Loss: 0.7878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_correct = 0\n",
        "num_samples = len(test_dataset)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for name, label in test_dataset:\n",
        "        hidden_state = model.init_hidden()\n",
        "        for char in name:\n",
        "            output, hidden_state = model(char, hidden_state)\n",
        "        _, pred = torch.max(output, dim=1)\n",
        "        num_correct += bool(pred == label)\n",
        "\n",
        "print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoCCN5Awn35Y",
        "outputId": "85fc9acb-fbf4-4956-de4e-6c4d37269bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 79.5217%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label2lang = {label.item(): lang for lang, label in lang2label.items()}\n",
        "\n",
        "def myrnn_predict(name):\n",
        "    model.eval()\n",
        "    tensor_name = name2tensor(name)\n",
        "    with torch.no_grad():\n",
        "        hidden_state = model.init_hidden()\n",
        "        for char in tensor_name:\n",
        "            output, hidden_state = model(char, hidden_state)\n",
        "        _, pred = torch.max(output, dim=1)\n",
        "    model.train()\n",
        "    return label2lang[pred.item()]"
      ],
      "metadata": {
        "id": "Z1KitqP0rca_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myrnn_predict(\"Khadija\")           # model acts poor as it's not predicting well."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aYdqP5cFrdgr",
        "outputId": "a1a90e25-91f6-4f5a-b9cc-1f0d3c4290d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Russian'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch GRU"
      ],
      "metadata": {
        "id": "KWnM7AmurTXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, num_layers, hidden_size):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=num_letters,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size, num_langs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden_state = self.init_hidden()\n",
        "        output, hidden_state = self.gru(x, hidden_state)\n",
        "        output = self.fc(output[-1])\n",
        "        return output\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(self.num_layers, 1, self.hidden_size).to(device)"
      ],
      "metadata": {
        "id": "7T7JXk6GoppJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = GRUModel(num_layers=2, hidden_size=hidden_size)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,)"
      ],
      "metadata": {
        "id": "jro96DajsSwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    random.shuffle(train_dataset)\n",
        "    for i, (name, label) in enumerate(train_dataset):\n",
        "        output = model_1(name)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % print_interval == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch + 1}/{10}], \"\n",
        "                f\"Step [{i + 1}/{len(train_dataset)}], \"\n",
        "                f\"Loss: {loss.item():.4f}\",\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqyJCajMsuqT",
        "outputId": "d287cbe5-5630-48e7-8d13-f1b391557ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [6000/18063], Loss: 2.8682\n",
            "Epoch [1/10], Step [12000/18063], Loss: 2.8760\n",
            "Epoch [1/10], Step [18000/18063], Loss: 2.8687\n",
            "Epoch [2/10], Step [6000/18063], Loss: 2.8848\n",
            "Epoch [2/10], Step [12000/18063], Loss: 2.8656\n",
            "Epoch [2/10], Step [18000/18063], Loss: 2.8584\n",
            "Epoch [3/10], Step [6000/18063], Loss: 2.8753\n",
            "Epoch [3/10], Step [12000/18063], Loss: 2.8752\n",
            "Epoch [3/10], Step [18000/18063], Loss: 2.8716\n",
            "Epoch [4/10], Step [6000/18063], Loss: 2.7990\n",
            "Epoch [4/10], Step [12000/18063], Loss: 2.8744\n",
            "Epoch [4/10], Step [18000/18063], Loss: 2.8805\n",
            "Epoch [5/10], Step [6000/18063], Loss: 2.8860\n",
            "Epoch [5/10], Step [12000/18063], Loss: 2.8718\n",
            "Epoch [5/10], Step [18000/18063], Loss: 2.8742\n",
            "Epoch [6/10], Step [6000/18063], Loss: 2.8719\n",
            "Epoch [6/10], Step [12000/18063], Loss: 2.8707\n",
            "Epoch [6/10], Step [18000/18063], Loss: 2.8748\n",
            "Epoch [7/10], Step [6000/18063], Loss: 2.9220\n",
            "Epoch [7/10], Step [12000/18063], Loss: 2.9088\n",
            "Epoch [7/10], Step [18000/18063], Loss: 2.8620\n",
            "Epoch [8/10], Step [6000/18063], Loss: 2.8796\n",
            "Epoch [8/10], Step [12000/18063], Loss: 2.8706\n",
            "Epoch [8/10], Step [18000/18063], Loss: 2.9650\n",
            "Epoch [9/10], Step [6000/18063], Loss: 2.8832\n",
            "Epoch [9/10], Step [12000/18063], Loss: 2.8746\n",
            "Epoch [9/10], Step [18000/18063], Loss: 2.8868\n",
            "Epoch [10/10], Step [6000/18063], Loss: 2.8758\n",
            "Epoch [10/10], Step [12000/18063], Loss: 2.8884\n",
            "Epoch [10/10], Step [18000/18063], Loss: 2.8763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for name, label in test_dataset:\n",
        "        output = model_1(name)\n",
        "        _, pred = torch.max(output, dim=1)\n",
        "        num_correct += bool(pred == label)\n",
        "\n",
        "print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TU1V5y_vGZf",
        "outputId": "e851ce19-a011-43d8-ec87-56b4641ba630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.4948%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pytorch_predict(name):\n",
        "    model_1.eval()\n",
        "    tensor_name = name2tensor(name)\n",
        "    with torch.no_grad():\n",
        "        output = model_1(tensor_name)\n",
        "        _, pred = torch.max(output, dim=1)\n",
        "    model_1.train()\n",
        "    return label2lang[pred.item()]"
      ],
      "metadata": {
        "id": "D-0hmn8l5VD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_predict(\"mqin\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "P7L2t9pm5kHF",
        "outputId": "1a23ed08-370d-45c5-b9f6-72483a72026d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Spanish'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I guess we've had some trouble traininig the RNN which is Pytorch + GRU.... see the accuracy -- 1.4% -- :(((\n",
        "# Let's give it a go next time :)"
      ],
      "metadata": {
        "id": "QFI3OdLa5rDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
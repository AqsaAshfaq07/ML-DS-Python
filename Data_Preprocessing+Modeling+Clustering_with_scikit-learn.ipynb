{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45b31a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc76106",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winequality_red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c1fbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity            1.741096\n",
       "volatile acidity         0.179060\n",
       "citric acid              0.194801\n",
       "residual sugar           1.409928\n",
       "chlorides                0.047065\n",
       "free sulfur dioxide     10.460157\n",
       "total sulfur dioxide    32.895324\n",
       "density                  0.001887\n",
       "pH                       0.154386\n",
       "sulphates                0.169507\n",
       "alcohol                  1.065668\n",
       "quality                  0.807569\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.std()  # overall data std is reduced to one by standardizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a6c98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52835961,  0.96187667, -1.39147228, ..., -0.57920652,\n",
       "        -0.96024611, -0.78782264],\n",
       "       [-0.29854743,  1.96744245, -1.39147228, ...,  0.1289504 ,\n",
       "        -0.58477711, -0.78782264],\n",
       "       [-0.29854743,  1.29706527, -1.18607043, ..., -0.04808883,\n",
       "        -0.58477711, -0.78782264],\n",
       "       ...,\n",
       "       [-1.1603431 , -0.09955388, -0.72391627, ...,  0.54204194,\n",
       "         0.54162988,  0.45084835],\n",
       "       [-1.39015528,  0.65462046, -0.77526673, ...,  0.30598963,\n",
       "        -0.20930812, -0.78782264],\n",
       "       [-1.33270223, -1.21684919,  1.02199944, ...,  0.01092425,\n",
       "         0.54162988,  0.45084835]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb04bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.describe()  # overall statistical measures aren't computed after standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c5fc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.247788</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.106845</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.098940</td>\n",
       "      <td>0.567548</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.137725</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.283186</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.143573</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>0.215548</td>\n",
       "      <td>0.494126</td>\n",
       "      <td>0.362205</td>\n",
       "      <td>0.209581</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283186</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.133556</td>\n",
       "      <td>0.197183</td>\n",
       "      <td>0.169611</td>\n",
       "      <td>0.508811</td>\n",
       "      <td>0.409449</td>\n",
       "      <td>0.191617</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.584071</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.105175</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.190813</td>\n",
       "      <td>0.582232</td>\n",
       "      <td>0.330709</td>\n",
       "      <td>0.149701</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.247788</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.106845</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.098940</td>\n",
       "      <td>0.567548</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.137725</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0.141593</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.075342</td>\n",
       "      <td>0.130217</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.134276</td>\n",
       "      <td>0.354626</td>\n",
       "      <td>0.559055</td>\n",
       "      <td>0.149701</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>0.115044</td>\n",
       "      <td>0.294521</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.089041</td>\n",
       "      <td>0.083472</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.159011</td>\n",
       "      <td>0.370778</td>\n",
       "      <td>0.614173</td>\n",
       "      <td>0.257485</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>0.150442</td>\n",
       "      <td>0.267123</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.106845</td>\n",
       "      <td>0.394366</td>\n",
       "      <td>0.120141</td>\n",
       "      <td>0.416300</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>0.251497</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0.115044</td>\n",
       "      <td>0.359589</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.075342</td>\n",
       "      <td>0.105175</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.134276</td>\n",
       "      <td>0.396476</td>\n",
       "      <td>0.653543</td>\n",
       "      <td>0.227545</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.130137</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>0.091820</td>\n",
       "      <td>0.239437</td>\n",
       "      <td>0.127208</td>\n",
       "      <td>0.397944</td>\n",
       "      <td>0.511811</td>\n",
       "      <td>0.197605</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0          0.247788          0.397260         0.00        0.068493   0.106845   \n",
       "1          0.283186          0.520548         0.00        0.116438   0.143573   \n",
       "2          0.283186          0.438356         0.04        0.095890   0.133556   \n",
       "3          0.584071          0.109589         0.56        0.068493   0.105175   \n",
       "4          0.247788          0.397260         0.00        0.068493   0.106845   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594       0.141593          0.328767         0.08        0.075342   0.130217   \n",
       "1595       0.115044          0.294521         0.10        0.089041   0.083472   \n",
       "1596       0.150442          0.267123         0.13        0.095890   0.106845   \n",
       "1597       0.115044          0.359589         0.12        0.075342   0.105175   \n",
       "1598       0.123894          0.130137         0.47        0.184932   0.091820   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "0                0.140845              0.098940  0.567548  0.606299   \n",
       "1                0.338028              0.215548  0.494126  0.362205   \n",
       "2                0.197183              0.169611  0.508811  0.409449   \n",
       "3                0.225352              0.190813  0.582232  0.330709   \n",
       "4                0.140845              0.098940  0.567548  0.606299   \n",
       "...                   ...                   ...       ...       ...   \n",
       "1594             0.436620              0.134276  0.354626  0.559055   \n",
       "1595             0.535211              0.159011  0.370778  0.614173   \n",
       "1596             0.394366              0.120141  0.416300  0.535433   \n",
       "1597             0.436620              0.134276  0.396476  0.653543   \n",
       "1598             0.239437              0.127208  0.397944  0.511811   \n",
       "\n",
       "      sulphates   alcohol  quality  \n",
       "0      0.137725  0.153846      0.4  \n",
       "1      0.209581  0.215385      0.4  \n",
       "2      0.191617  0.215385      0.4  \n",
       "3      0.149701  0.215385      0.6  \n",
       "4      0.137725  0.153846      0.4  \n",
       "...         ...       ...      ...  \n",
       "1594   0.149701  0.323077      0.4  \n",
       "1595   0.257485  0.430769      0.6  \n",
       "1596   0.251497  0.400000      0.6  \n",
       "1597   0.227545  0.276923      0.4  \n",
       "1598   0.197605  0.400000      0.6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Range Scaling\n",
    "x = (data - data.min()) / (data.max() - data.min())\n",
    "x  # all values are converted to 0-1 range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17068005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24778761 0.39726027 0.         ... 0.13772455 0.15384615 0.4       ]\n",
      " [0.28318584 0.52054795 0.         ... 0.20958084 0.21538462 0.4       ]\n",
      " [0.28318584 0.43835616 0.04       ... 0.19161677 0.21538462 0.4       ]\n",
      " ...\n",
      " [0.15044248 0.26712329 0.13       ... 0.25149701 0.4        0.6       ]\n",
      " [0.11504425 0.35958904 0.12       ... 0.22754491 0.27692308 0.4       ]\n",
      " [0.12389381 0.13013699 0.47       ... 0.19760479 0.4        0.6       ]]\n"
     ]
    }
   ],
   "source": [
    "# Range Compression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "default_scale = MinMaxScaler()\n",
    "transformed = default_scale.fit_transform(data)\n",
    "print(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4453bb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24778761 0.39726027 0.         ... 0.13772455 0.15384615 0.4       ]\n",
      " [0.28318584 0.52054795 0.         ... 0.20958084 0.21538462 0.4       ]\n",
      " [0.28318584 0.43835616 0.04       ... 0.19161677 0.21538462 0.4       ]\n",
      " ...\n",
      " [0.15044248 0.26712329 0.13       ... 0.25149701 0.4        0.6       ]\n",
      " [0.11504425 0.35958904 0.12       ... 0.22754491 0.27692308 0.4       ]\n",
      " [0.12389381 0.13013699 0.47       ... 0.19760479 0.4        0.6       ]]\n"
     ]
    }
   ],
   "source": [
    "new_data = data.copy()\n",
    "\n",
    "# fit_transform on this new_data\n",
    "pred = default_scale.fit_transform(new_data)\n",
    "\n",
    "# fit and transform separate function calls\n",
    "default_scale.fit(data)\n",
    "pred = default_scale.transform(new_data)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88629032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23809524,  0.72      , -0.78787879, ..., -0.33333333,\n",
       "        -0.5       , -1.        ],\n",
       "       [-0.04761905,  1.44      , -0.78787879, ...,  0.33333333,\n",
       "        -0.25      , -1.        ],\n",
       "       [-0.04761905,  0.96      , -0.66666667, ...,  0.16666667,\n",
       "        -0.25      , -1.        ],\n",
       "       ...,\n",
       "       [-0.76190476, -0.04      , -0.39393939, ...,  0.72222222,\n",
       "         0.5       ,  0.        ],\n",
       "       [-0.95238095,  0.5       , -0.42424242, ...,  0.5       ,\n",
       "         0.        , -1.        ],\n",
       "       [-0.9047619 , -0.84      ,  0.63636364, ...,  0.22222222,\n",
       "         0.5       ,  0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Escaping the Outliers\n",
    "\n",
    "# To perform robust scaling with scikit learn to deal with outliers\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaled_data = RobustScaler().fit_transform(data)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6df2b9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19347777, 0.01830195, 0.        , ..., 0.01464156, 0.24576906,\n",
       "        0.13072822],\n",
       "       [0.10698874, 0.01207052, 0.        , ..., 0.00932722, 0.13442175,\n",
       "        0.06858252],\n",
       "       [0.13494887, 0.01314886, 0.00069205, ..., 0.01124574, 0.16955114,\n",
       "        0.08650569],\n",
       "       ...,\n",
       "       [0.1222319 , 0.00989496, 0.00252225, ..., 0.01455142, 0.21342078,\n",
       "        0.11641133],\n",
       "       [0.10524769, 0.01150589, 0.00214063, ..., 0.0126654 , 0.18195363,\n",
       "        0.08919296],\n",
       "       [0.12491328, 0.00645385, 0.00978487, ..., 0.01374046, 0.22900768,\n",
       "        0.12491328]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2 Normalization -- Normalizer -- avoid all this lengthy computation\n",
    "# for x in row : (x1 / ((x1^2+...+xn^2)^0.5)) + ... + (xn / ((x1^2+...+xn^2)^0.5))\n",
    "\n",
    "from sklearn.preprocessing import Normalizer \n",
    "Normalizer().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24a7c171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 2.01400000e+03, 1.21000000e+02, ...,\n",
       "        7.57074000e+05, 3.33130000e+02, 7.60000000e+01],\n",
       "       [2.00000000e+00, 2.01200000e+03, 1.24000000e+02, ...,\n",
       "        4.85820000e+05, 1.26460000e+02, 6.50000000e+01],\n",
       "       [3.00000000e+00, 2.01600000e+03, 1.17000000e+02, ...,\n",
       "        1.57606000e+05, 1.38120000e+02, 6.20000000e+01],\n",
       "       ...,\n",
       "       [9.98000000e+02, 2.00800000e+03, 9.80000000e+01, ...,\n",
       "        7.06990000e+04, 5.80100000e+01, 5.00000000e+01],\n",
       "       [9.99000000e+02, 2.01400000e+03, 9.30000000e+01, ...,\n",
       "        4.88100000e+03, 8.29563761e+01, 2.20000000e+01],\n",
       "       [1.00000000e+03, 2.01600000e+03, 8.70000000e+01, ...,\n",
       "        1.24350000e+04, 1.96400000e+01, 1.10000000e+01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Imputation/Replacement - tackling missing data - using SimpleImputer\n",
    "dummy = pd.read_csv('IMDB-Movie-Data.csv')  # this dataset contains some null values \n",
    "from sklearn.impute import SimpleImputer\n",
    "# \n",
    "dummy = dummy.drop('Genre', axis = 1)\n",
    "dummy = dummy.drop('Title', axis = 1)\n",
    "dummy = dummy.drop('Description', axis = 1)\n",
    "dummy = dummy.drop('Director', axis = 1)\n",
    "dummy = dummy.drop('Actors', axis = 1)\n",
    "dummy = SimpleImputer(strategy = 'mean', fill_value = 1).fit_transform(dummy)  # strategy = mean/median/most_frequent/constant_value\n",
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da93109b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-13.22202658,  -2.03192212,  -1.18123474,  -0.47564207],\n",
       "       [ 22.04025471,   4.40179054,  -0.35499069,  -0.2602393 ],\n",
       "       [  7.16536169,  -2.50832073,  -0.62463767,  -0.27530638],\n",
       "       ...,\n",
       "       [ -3.43293096,  14.27427694,  -1.73227854,   0.21146278],\n",
       "       [  1.13557385,  16.30769238,  -2.18955318,  -0.294478  ],\n",
       "       [ -3.87592057,   3.13011173,  -1.84248483,   1.73878746]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "PCA(n_components=4).fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34dcca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('quality', axis = 1)\n",
    "y = data['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aef7beaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "bc = load_breast_cancer()\n",
    "bc.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec8af68",
   "metadata": {},
   "source": [
    "# Data Modeling with Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90f4a42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       " 925             8.6             0.220         0.36             1.9      0.064   \n",
       " 363            12.5             0.460         0.63             2.0      0.071   \n",
       " 906             7.2             0.540         0.27             2.6      0.084   \n",
       " 426             6.4             0.670         0.08             2.1      0.045   \n",
       " 1251            7.5             0.580         0.14             2.2      0.077   \n",
       " ...             ...               ...          ...             ...        ...   \n",
       " 1130            9.1             0.600         0.00             1.9      0.058   \n",
       " 1294            8.2             0.635         0.10             2.1      0.073   \n",
       " 860             7.2             0.620         0.06             2.7      0.077   \n",
       " 1459            7.9             0.200         0.35             1.7      0.054   \n",
       " 1126            5.8             0.290         0.26             1.7      0.063   \n",
       " \n",
       "       free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       " 925                  53.0                  77.0  0.99604  3.47       0.87   \n",
       " 363                   6.0                  15.0  0.99880  2.99       0.87   \n",
       " 906                  12.0                  78.0  0.99640  3.39       0.71   \n",
       " 426                  19.0                  48.0  0.99490  3.49       0.49   \n",
       " 1251                 27.0                  60.0  0.99630  3.28       0.59   \n",
       " ...                   ...                   ...      ...   ...        ...   \n",
       " 1130                  5.0                  10.0  0.99770  3.18       0.63   \n",
       " 1294                 25.0                  60.0  0.99638  3.29       0.75   \n",
       " 860                  15.0                  85.0  0.99746  3.51       0.54   \n",
       " 1459                  7.0                  15.0  0.99458  3.32       0.80   \n",
       " 1126                  3.0                  11.0  0.99150  3.39       0.54   \n",
       " \n",
       "       alcohol  \n",
       " 925      11.0  \n",
       " 363      10.2  \n",
       " 906      11.0  \n",
       " 426      11.4  \n",
       " 1251      9.8  \n",
       " ...       ...  \n",
       " 1130     10.4  \n",
       " 1294     10.9  \n",
       " 860       9.5  \n",
       " 1459     11.9  \n",
       " 1126     13.5  \n",
       " \n",
       " [1119 rows x 11 columns],\n",
       " 925     7\n",
       " 363     5\n",
       " 906     5\n",
       " 426     6\n",
       " 1251    5\n",
       "        ..\n",
       " 1130    6\n",
       " 1294    6\n",
       " 860     5\n",
       " 1459    7\n",
       " 1126    6\n",
       " Name: quality, Length: 1119, dtype: int64,\n",
       "       fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       " 803             7.7              0.56         0.08            2.50      0.114   \n",
       " 124             7.8              0.50         0.17            1.60      0.082   \n",
       " 350            10.7              0.67         0.22            2.70      0.107   \n",
       " 682             8.5              0.46         0.31            2.25      0.078   \n",
       " 1326            6.7              0.46         0.24            1.70      0.077   \n",
       " ...             ...               ...          ...             ...        ...   \n",
       " 1468            7.3              0.48         0.32            2.10      0.062   \n",
       " 495            10.7              0.35         0.53            2.60      0.070   \n",
       " 1325            6.7              0.46         0.24            1.70      0.077   \n",
       " 514            10.5              0.51         0.64            2.40      0.107   \n",
       " 576             9.9              0.50         0.24            2.30      0.103   \n",
       " \n",
       "       free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       " 803                  14.0                  46.0  0.99710  3.24       0.66   \n",
       " 124                  21.0                 102.0  0.99600  3.39       0.48   \n",
       " 350                  17.0                  34.0  1.00040  3.28       0.98   \n",
       " 682                  32.0                  58.0  0.99800  3.33       0.54   \n",
       " 1326                 18.0                  34.0  0.99480  3.39       0.60   \n",
       " ...                   ...                   ...      ...   ...        ...   \n",
       " 1468                 31.0                  54.0  0.99728  3.30       0.65   \n",
       " 495                   5.0                  16.0  0.99720  3.15       0.65   \n",
       " 1325                 18.0                  34.0  0.99480  3.39       0.60   \n",
       " 514                   6.0                  15.0  0.99730  3.09       0.66   \n",
       " 576                   6.0                  14.0  0.99780  3.34       0.52   \n",
       " \n",
       "       alcohol  \n",
       " 803       9.6  \n",
       " 124       9.5  \n",
       " 350       9.9  \n",
       " 682       9.8  \n",
       " 1326     10.6  \n",
       " ...       ...  \n",
       " 1468     10.0  \n",
       " 495      11.0  \n",
       " 1325     10.6  \n",
       " 514      11.8  \n",
       " 576      10.0  \n",
       " \n",
       " [480 rows x 11 columns],\n",
       " 803     6\n",
       " 124     5\n",
       " 350     6\n",
       " 682     5\n",
       " 1326    6\n",
       "        ..\n",
       " 1468    7\n",
       " 495     8\n",
       " 1325    6\n",
       " 514     7\n",
       " 576     4\n",
       " Name: quality, Length: 480, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression  -- already done above \n",
    "data\n",
    "X_train, y_train, X_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cb54f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34759998500181366"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge Regression -> uses L2 norm for regularization\n",
    "# For regularization -> alpha*(L2 norm of weights) + rmse val\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge(alpha = 0.9)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "reg.coef_\n",
    "reg.intercept_\n",
    "r2 = reg.score(X_test, y_test)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da1257c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3497341896138322"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Cross-validation to choose alpha from a list of values\n",
    "from sklearn import linear_model\n",
    "alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "reg = linear_model.RidgeCV(alphas = alphas)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddd788d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20887882853160988"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso Regression - L1 norm of weights - uses fewer parameter values\n",
    "# Sparse Regularization ->  Î±âˆ£âˆ£wâˆ£âˆ£1â€‹ + i=1âˆ‘nâ€‹ (x iâ€‹ â‹…wâˆ’y iâ€‹ ) 2  \n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.Lasso(alpha = 0.1)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "reg.coef_\n",
    "reg.intercept_\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "462eff77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20887882853160988"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also supports cross validation like in ridge regression using LassoCV\n",
    "from sklearn import linear_model\n",
    "alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "reg = linear_model.LassoCV(alphas = alpha)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "reg.coef_\n",
    "reg.intercept_\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27cde28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3461509706055187"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian Regression -> alpha, lambda-precision factor, \n",
    "from sklearn import linear_model\n",
    "# alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "reg = linear_model.BayesianRidge()  # don't take alpha/lambda parameter by default\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "reg.coef_\n",
    "reg.intercept_\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ccf4268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\SOFTWARES\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression -> binary classification\n",
    "reg = linear_model.LogisticRegression(max_iter = 10, multi_class = 'multinomial', solver = 'lbfgs', penalty = 'l2')\n",
    "reg.fit(X_train, y_train)\n",
    "reg_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5719bc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.48888889, 5.09876543, 5.48888889, 5.35714286, 5.98019802,\n",
       "       5.09876543, 5.29411765, 5.35714286, 6.27777778, 5.98019802,\n",
       "       6.92307692, 5.48888889, 5.48888889, 5.48888889, 5.675     ,\n",
       "       6.24137931, 5.35714286, 5.48888889, 6.94545455, 5.48888889,\n",
       "       5.09090909, 5.48888889, 5.64864865, 6.05882353, 5.48888889,\n",
       "       5.48888889, 6.05882353, 5.35714286, 4.94285714, 6.27777778,\n",
       "       5.35714286, 5.35714286, 5.675     , 5.35714286, 5.48888889,\n",
       "       5.09876543, 6.30882353, 5.98019802, 5.48888889, 6.24137931,\n",
       "       5.35714286, 5.09876543, 6.27777778, 5.29411765, 5.675     ,\n",
       "       5.48888889, 6.30882353, 5.675     , 5.64864865, 5.48888889,\n",
       "       4.94285714, 5.48888889, 5.98019802, 6.94545455, 5.48888889,\n",
       "       4.94285714, 5.98019802, 5.48888889, 5.64864865, 5.48888889,\n",
       "       5.48888889, 6.30882353, 5.09876543, 5.09876543, 6.43478261,\n",
       "       5.09876543, 6.92307692, 5.48888889, 6.94545455, 5.29411765,\n",
       "       6.24137931, 4.94285714, 5.675     , 5.64864865, 6.05882353,\n",
       "       5.09876543, 6.43478261, 5.21428571, 6.05882353, 6.94545455,\n",
       "       5.48888889, 6.94545455, 5.48888889, 5.09090909, 5.98019802,\n",
       "       6.43478261, 5.09876543, 5.98019802, 6.30882353, 5.48888889,\n",
       "       6.43478261, 5.64864865, 5.09090909, 5.09090909, 4.8       ,\n",
       "       5.675     , 5.35714286, 5.48888889, 4.86666667, 5.35714286,\n",
       "       3.        , 5.09876543, 5.98019802, 5.98019802, 5.64864865,\n",
       "       6.30882353, 5.675     , 5.29411765, 5.64864865, 5.48888889,\n",
       "       6.43478261, 5.09876543, 6.27777778, 4.94285714, 5.35714286,\n",
       "       5.6       , 5.09090909, 5.35714286, 5.09876543, 5.64864865,\n",
       "       6.24137931, 5.48888889, 5.48888889, 5.09090909, 5.48888889,\n",
       "       5.09876543, 6.30882353, 5.48888889, 5.48888889, 5.64864865,\n",
       "       5.675     , 5.48888889, 5.09876543, 6.05882353, 5.48888889,\n",
       "       5.09876543, 5.09876543, 5.09876543, 5.35714286, 5.98019802,\n",
       "       5.675     , 6.27777778, 6.30882353, 5.09090909, 5.675     ,\n",
       "       5.48888889, 5.64864865, 5.64864865, 5.21428571, 5.29411765,\n",
       "       5.48888889, 5.98019802, 5.09876543, 5.48888889, 5.675     ,\n",
       "       6.30882353, 5.48888889, 6.27777778, 5.35714286, 5.98019802,\n",
       "       6.30882353, 5.6       , 6.43478261, 4.94285714, 5.35714286,\n",
       "       5.48888889, 5.66666667, 5.09876543, 4.8       , 5.29411765,\n",
       "       5.09876543, 5.09876543, 6.24137931, 5.35714286, 6.24137931,\n",
       "       5.98019802, 6.27777778, 5.09876543, 5.09876543, 5.21428571,\n",
       "       5.66666667, 6.30882353, 5.29411765, 6.24137931, 5.09876543,\n",
       "       6.43478261, 5.98019802, 5.98019802, 6.94545455, 5.35714286,\n",
       "       5.48888889, 5.98019802, 5.35714286, 6.05882353, 5.6       ,\n",
       "       5.09876543, 3.        , 5.675     , 5.48888889, 6.30882353,\n",
       "       5.48888889, 5.29411765, 5.09876543, 5.35714286, 6.43478261,\n",
       "       5.64864865, 5.09876543, 5.09876543, 5.675     , 6.        ,\n",
       "       6.94545455, 4.94285714, 5.675     , 6.43478261, 6.24137931,\n",
       "       5.64864865, 5.48888889, 5.48888889, 5.64864865, 5.48888889,\n",
       "       5.48888889, 6.43478261, 6.05882353, 6.27777778, 4.        ,\n",
       "       4.86666667, 5.09876543, 6.94545455, 4.8       , 5.48888889,\n",
       "       4.94285714, 5.09876543, 6.24137931, 5.98019802, 5.98019802,\n",
       "       6.30882353, 5.35714286, 5.98019802, 5.48888889, 5.09876543,\n",
       "       5.48888889, 5.09876543, 5.09090909, 6.30882353, 5.675     ,\n",
       "       5.48888889, 5.48888889, 5.48888889, 6.05882353, 5.35714286,\n",
       "       5.6       , 5.35714286, 5.48888889, 5.48888889, 5.98019802,\n",
       "       5.48888889, 5.48888889, 5.09090909, 5.48888889, 6.43478261,\n",
       "       6.94545455, 5.09090909, 5.09876543, 6.24137931, 5.48888889,\n",
       "       6.30882353, 5.48888889, 5.29411765, 6.30882353, 6.05882353,\n",
       "       5.09876543, 5.98019802, 5.675     , 5.29411765, 5.48888889,\n",
       "       5.35714286, 5.6       , 6.43478261, 6.30882353, 5.48888889,\n",
       "       6.94545455, 5.09876543, 5.48888889, 5.35714286, 5.48888889,\n",
       "       5.64864865, 5.09876543, 6.27777778, 5.48888889, 6.05882353,\n",
       "       5.35714286, 6.94545455, 5.675     , 5.29411765, 5.29411765,\n",
       "       6.05882353, 5.35714286, 6.92307692, 6.30882353, 6.24137931,\n",
       "       5.09876543, 5.09876543, 6.30882353, 3.        , 5.48888889,\n",
       "       5.09876543, 5.98019802, 5.48888889, 5.09090909, 6.94545455,\n",
       "       5.35714286, 5.64864865, 5.35714286, 5.48888889, 5.35714286,\n",
       "       5.98019802, 5.09876543, 5.35714286, 6.30882353, 5.09876543,\n",
       "       6.43478261, 6.05882353, 6.27777778, 5.09876543, 4.86666667,\n",
       "       6.27777778, 6.43478261, 5.98019802, 4.94285714, 6.27777778,\n",
       "       5.64864865, 6.94545455, 5.29411765, 5.48888889, 5.675     ,\n",
       "       5.98019802, 6.05882353, 6.27777778, 5.09876543, 4.94285714,\n",
       "       6.43478261, 6.94545455, 5.09090909, 5.48888889, 5.48888889,\n",
       "       5.09876543, 6.05882353, 5.48888889, 5.48888889, 5.6       ,\n",
       "       5.48888889, 6.24137931, 5.09876543, 4.94285714, 5.48888889,\n",
       "       5.48888889, 5.48888889, 5.48888889, 5.64864865, 5.64864865,\n",
       "       5.98019802, 5.48888889, 5.35714286, 5.35714286, 4.94285714,\n",
       "       5.98019802, 5.48888889, 5.29411765, 5.29411765, 5.09876543,\n",
       "       5.21428571, 5.09876543, 5.98019802, 5.09090909, 5.675     ,\n",
       "       6.24137931, 5.48888889, 6.30882353, 5.48888889, 5.09876543,\n",
       "       5.35714286, 5.09090909, 6.05882353, 5.48888889, 6.30882353,\n",
       "       5.48888889, 6.30882353, 4.94285714, 4.8       , 5.64864865,\n",
       "       5.35714286, 5.35714286, 5.09876543, 5.35714286, 6.05882353,\n",
       "       5.98019802, 5.98019802, 5.48888889, 5.48888889, 6.30882353,\n",
       "       5.09876543, 5.09876543, 5.64864865, 4.94285714, 5.98019802,\n",
       "       5.98019802, 6.94545455, 6.05882353, 5.29411765, 5.48888889,\n",
       "       5.48888889, 6.94545455, 6.27777778, 6.27777778, 5.64864865,\n",
       "       5.48888889, 5.29411765, 6.43478261, 5.35714286, 6.94545455,\n",
       "       6.24137931, 5.35714286, 5.21428571, 5.09876543, 5.675     ,\n",
       "       5.48888889, 5.09876543, 5.09876543, 5.98019802, 5.35714286,\n",
       "       6.94545455, 5.29411765, 5.09876543, 5.09876543, 6.30882353,\n",
       "       5.29411765, 5.48888889, 5.09876543, 4.86666667, 5.64864865,\n",
       "       5.64864865, 6.27777778, 6.94545455, 5.48888889, 5.48888889,\n",
       "       5.21428571, 5.48888889, 5.6       , 5.48888889, 5.48888889,\n",
       "       5.98019802, 5.98019802, 5.09090909, 5.09876543, 5.675     ,\n",
       "       5.98019802, 6.94545455, 4.94285714, 5.64864865, 4.94285714,\n",
       "       5.48888889, 5.64864865, 5.48888889, 5.09876543, 5.09090909,\n",
       "       5.29411765, 5.48888889, 5.48888889, 6.        , 5.64864865,\n",
       "       6.92307692, 5.64864865, 5.98019802, 5.98019802, 5.48888889,\n",
       "       5.48888889, 6.30882353, 5.98019802, 6.92307692, 5.35714286])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Trees -> CLassification + Regression\n",
    "from sklearn import tree\n",
    "clf_tree = tree.DecisionTreeClassifier(max_depth = 8) # max_depth  -> no. of levels/layers\n",
    "reg_tree = tree.DecisionTreeRegressor(max_depth = 5)\n",
    "clf_tree.fit(X_train, y_train)\n",
    "reg_tree.fit(X_train, y_train)\n",
    "clf_tree.predict(X_test)\n",
    "reg_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "621ee516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction -> choosing best no. of features depending on the Gini Impurity(classification), MSE, MAE -> (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c96e1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing\n",
    "# from sklearn.model_selection import train_test_split()\n",
    "# X_train, y_train, X_test, y_test = train_test_split(X, y, test_size = 0.25 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32b70600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49718574 0.48592871 0.43714822]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\SOFTWARES\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\SOFTWARES\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\SOFTWARES\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv_score = cross_val_score(reg, X, y, cv = 3)\n",
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2c79ba8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cross_val_score() takes from 2 to 3 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12512\\915117045.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mis_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mstd_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_val_score() takes from 2 to 3 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "is_clf = True\n",
    "for depth in range(3, 8):\n",
    "    scores = cross_val_score(is_clf, X, y, depth, 5)\n",
    "    mean = scores.mean()\n",
    "    std_2 = 2 * scores.std()\n",
    "    \n",
    "print(depth, mean, std_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "86e8dbb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (11!=1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12512\\3391036767.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#error2 = metrics.mean_squared_error(X_test, reg_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SOFTWARES\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;33m-\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m     \"\"\"\n\u001b[1;32m--> 789\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    790\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m     )\n",
      "\u001b[1;32mE:\\SOFTWARES\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    106\u001b[0m             \"y_true and y_pred have different number of output ({0}!={1})\".format(\n\u001b[0;32m    107\u001b[0m                 \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (11!=1)"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "error = metrics.r2_score(X_test, reg_pred)\n",
    "#error2 = metrics.mean_squared_error(X_test, reg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bfd1de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Classification Error Calculation -> use accuracy_score\n",
    "# For Regression Error Calculation -> use mse, mae, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "726a4353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha_1': 0.3, 'alpha_2': 0.1}\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.BayesianRidge()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "  'alpha_1':[0.1,0.2,0.3],\n",
    "  'alpha_2':[0.1,0.2,0.3]\n",
    "}\n",
    "reg_cv = GridSearchCV(reg, params, cv=5)\n",
    "# predefined trairing and test sets\n",
    "reg_cv.fit( X_train, y_train)\n",
    "print(reg_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910e77a0",
   "metadata": {},
   "source": [
    "# CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4063478b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.98479324, 0.99225115, ..., 0.95224146, 0.94713022,\n",
       "        0.99291264],\n",
       "       [0.98479324, 1.        , 0.99514183, ..., 0.9609342 , 0.9634775 ,\n",
       "        0.99105198],\n",
       "       [0.99225115, 0.99514183, 1.        , ..., 0.93997629, 0.93982573,\n",
       "        0.98822294],\n",
       "       ...,\n",
       "       [0.95224146, 0.9609342 , 0.93997629, ..., 1.        , 0.99886991,\n",
       "        0.97684733],\n",
       "       [0.94713022, 0.9634775 , 0.93982573, ..., 0.99886991, 1.        ,\n",
       "        0.9739885 ],\n",
       "       [0.99291264, 0.99105198, 0.98822294, ..., 0.97684733, 0.9739885 ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measuring Similarity -> cosine similarity -> dot product of L2 norm of two vectors, [-1, 1] ,, 0 -> no similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ddc07585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   4,    0,  123,  262, 1380, 1379],\n",
       "       [   1,  752, 1314, 1174, 1173, 1357],\n",
       "       [   2,  196,  224,   58, 1361,   63],\n",
       "       ...,\n",
       "       [1592, 1596, 1542, 1593, 1565,  897],\n",
       "       [1597, 1594, 1046,  670, 1273,  877],\n",
       "       [1598,  571,  569,  995, 1335,   85]], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors  # returns distance of all neighbors from the input data observation\n",
    "nbrs = NearestNeighbors(n_neighbors = 6) # default-val = 5\n",
    "nbrs.fit(data)\n",
    "dists, knbrs = nbrs.kneighbors(data)  # ~= predict function with other algorithms\n",
    "knbrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "682fe2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-Means Clustering -> iterative approach , produces spherical clusters\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters = 3)\n",
    "var2 = kmeans.fit(data)\n",
    "\n",
    "# checking the cluster assignments \n",
    "kmeans.labels_  # cluster assignment for each data observation\n",
    "kmeans.cluster_centers_  # final centroids\n",
    "kmeans.predict(data)  # assigns random new clusters to observations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5a71e311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\SOFTWARES\\ANACONDA\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1043: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mini Batch kmeans clustering\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "mini = MiniBatchKMeans(batch_size = 10, n_clusters = 3)\n",
    "mini.fit(data)\n",
    "mini.labels_  \n",
    "mini.cluster_centers_  \n",
    "mini.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fb64a23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 1, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hirerchical Clustering -> bottom-up (divisive), top-down (agglomerative) (like merge sort)\n",
    "# Agglomerative Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "agg = AgglomerativeClustering(n_clusters = 5)\n",
    "agg.fit(data)\n",
    "agg.labels_\n",
    "# agg.cluster_centers_ -> don't contain this bcz it don't make use of any centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abbbb38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
